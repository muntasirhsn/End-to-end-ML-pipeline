{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec3f685b",
   "metadata": {
    "papermill": {
     "duration": 0.023216,
     "end_time": "2022-08-21T06:37:58.272854",
     "exception": false,
     "start_time": "2022-08-21T06:37:58.249638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577aaa35",
   "metadata": {
    "papermill": {
     "duration": 3.047443,
     "end_time": "2022-08-21T06:38:01.339242",
     "exception": false,
     "start_time": "2022-08-21T06:37:58.291799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Start counting notebook running time\n",
    "time_start = time.time()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet, Ridge, LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# Mute warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746536f0-414d-475b-9af0-4286de759843",
   "metadata": {},
   "source": [
    "## Import train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8bcfb70-c2d9-472a-a016-f380a19e99de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size:  (1460, 80)\n",
      "test data size:  (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "train = pd.read_csv(\"train.csv\", index_col=\"Id\")\n",
    "X_train = train.copy()\n",
    "print('train data size: ', X_train.shape)\n",
    "y_train = X_train.pop(\"SalePrice\")\n",
    "\n",
    "# Test data\n",
    "test = pd.read_csv(\"test.csv\", index_col=\"Id\")\n",
    "X_test = test.copy()\n",
    "print('test data size: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5350a0-482e-4c78-b316-df893e938d6f",
   "metadata": {},
   "source": [
    "## Define all data preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a83ec6-f234-4fde-8da6-37cf7b75eaad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Renaming some features\n",
    "# Feature names beginning with numbers are awkward to work with, so we rename them\n",
    "def rename_columns(df):\n",
    "    X = df.copy()\n",
    "    # Names beginning with numbers are awkward to work with\n",
    "    X.rename(columns={\"1stFlrSF\": \"FirstFlrSF\",\n",
    "                       \"2ndFlrSF\": \"SecondFlrSF\",\n",
    "                       \"3SsnPorch\": \"Threeseasonporch\"},\n",
    "              inplace=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3dfc49f-2365-4894-8e04-c0e0e0e3589d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "def clean(df):\n",
    "    X = df.copy()\n",
    "    X[\"Exterior2nd\"] = X[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n",
    "    \n",
    "    # Some values of GarageYrBlt are corrupt, so we'll replace them with the year the house was built\n",
    "    X[\"GarageYrBlt\"] = X[\"GarageYrBlt\"].where(X.GarageYrBlt <= 2010, X.YearBuilt)\n",
    "    \n",
    "    # Some values of YrSold are also corrupt i.e. house was sold before it was built! We'll replace them with the year the house was built\n",
    "    X[\"YrSold\"] = X[\"YrSold\"].where(X.YrSold >= X.YearBuilt, X.YearBuilt)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131af911-6a99-4631-9606-4267f970bcd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The 'MSSubClass' is a string/unordered(nominal) categorical variable but encoded as `int` type. So we need to convert the data type. \n",
    "other_categorical_features = ['MSSubClass'] \n",
    "\n",
    "def numer_to_object(df):\n",
    "    X = df.copy()\n",
    "    for name in other_categorical_features:\n",
    "        X[name] = X[name].astype('str')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "861fe22e-b0fe-4622-a34f-d90bc22e42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing Values\n",
    "def impute(df):\n",
    "    X = df.copy()\n",
    "    for name in X.select_dtypes(\"number\"):\n",
    "        X[name] = X[name].fillna(0)\n",
    "    for name in X.select_dtypes(\"O\"):\n",
    "        X[name] = X[name].fillna(\"None\") \n",
    "    for name in X.select_dtypes(\"category\"):\n",
    "        X[name] = X[name].fillna(\"None\") \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b10ba69-f130-403b-8085-ca4d8f13c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features: ordianl encoding\n",
    "# Some of the categorical features are ordered so we need to correctly encode them with specific orders\n",
    "\n",
    "ordered_levels = {\n",
    "    \"ExterQual\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"ExterCond\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"BsmtQual\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"BsmtCond\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"HeatingQC\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"KitchenQual\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"FireplaceQu\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"GarageQual\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"GarageCond\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"PoolQC\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n",
    "    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n",
    "    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n",
    "    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n",
    "    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n",
    "    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n",
    "    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n",
    "    \"CentralAir\": [\"N\", \"Y\"],\n",
    "    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n",
    "    \"Fence\": [\"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n",
    "}\n",
    "\n",
    "# add a new category 'None' in each ordinal categorical feature so that we can replace NAs with a category 'None'.\n",
    "ordered_levels = {key: [\"None\"] + value for key, value in ordered_levels.items()} # the 1st level is 'None'\n",
    "\n",
    "def ordinal_encode(df):\n",
    "    X = df.copy()\n",
    "    # Ordinal categories\n",
    "    for name, levels in ordered_levels.items():\n",
    "        X[name] = X[name].astype(CategoricalDtype(levels, ordered=True)) \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b1c6e9-64d6-43a9-9968-e5ec33445eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_levels = {'MSSubClass': ['None', '60', '20', '70', '50', '190', '45', '90', '120', '30', '85', '80', '160', '75', '180', '40'], \n",
    "          'MSZoning': ['None', 'RL', 'RM', 'C (all)', 'FV', 'RH'], \n",
    "          'Street': ['None', 'Pave', 'Grvl'], \n",
    "          'Alley': ['None', 'Grvl', 'Pave'], \n",
    "          'LandContour': ['None', 'Lvl', 'Bnk', 'Low', 'HLS'], \n",
    "          'LotConfig': ['None', 'Inside', 'FR2', 'Corner', 'CulDSac', 'FR3'], \n",
    "          'Neighborhood': ['None', 'CollgCr', 'Veenker', 'Crawfor', 'NoRidge', 'Mitchel', 'Somerst', 'NWAmes', 'OldTown', 'BrkSide', 'Sawyer', 'NridgHt', 'NAmes', 'SawyerW', 'IDOTRR', 'MeadowV', 'Edwards', 'Timber', 'Gilbert', 'StoneBr', 'ClearCr', 'NPkVill', 'Blmngtn', 'BrDale', 'SWISU', 'Blueste'], \n",
    "          'Condition1': ['None', 'Norm', 'Feedr', 'PosN', 'Artery', 'RRAe', 'RRNn', 'RRAn', 'PosA', 'RRNe'], \n",
    "          'Condition2': ['None', 'Norm', 'Artery', 'RRNn', 'Feedr', 'PosN', 'PosA', 'RRAn', 'RRAe'], \n",
    "          'BldgType': ['None', '1Fam', '2fmCon', 'Duplex', 'TwnhsE', 'Twnhs'], \n",
    "          'HouseStyle': ['None', '2Story', '1Story', '1.5Fin', '1.5Unf', 'SFoyer', 'SLvl', '2.5Unf', '2.5Fin'], \n",
    "          'RoofStyle': ['None', 'Gable', 'Hip', 'Gambrel', 'Mansard', 'Flat', 'Shed'], \n",
    "          'RoofMatl': ['None', 'CompShg', 'WdShngl', 'Metal', 'WdShake', 'Membran', 'Tar&Grv', 'Roll', 'ClyTile'], \n",
    "          'Exterior1st': ['None', 'VinylSd', 'MetalSd', 'Wd Sdng', 'HdBoard', 'BrkFace', 'WdShing', 'CemntBd', 'Plywood', 'AsbShng', 'Stucco', 'BrkComm', 'AsphShn', 'Stone', 'ImStucc', 'CBlock'], \n",
    "          'Exterior2nd': ['None', 'VinylSd', 'MetalSd', 'Wd Shng', 'HdBoard', 'Plywood', 'Wd Sdng', 'CmentBd', 'BrkFace', 'Stucco', 'AsbShng', 'BrkComm', 'ImStucc', 'AsphShn', 'Stone', 'Other', 'CBlock'], \n",
    "          'MasVnrType': ['BrkFace', 'None', 'Stone', 'BrkCmn'], \n",
    "          'Foundation': ['None', 'PConc', 'CBlock', 'BrkTil', 'Wood', 'Slab', 'Stone'], \n",
    "          'Heating': ['None', 'GasA', 'GasW', 'Grav', 'Wall', 'OthW', 'Floor'], \n",
    "          'GarageType': ['Attchd', 'Detchd', 'BuiltIn', 'CarPort', 'None', 'Basment', '2Types'], \n",
    "          'MiscFeature': ['None', 'Shed', 'Gar2', 'Othr', 'TenC'], \n",
    "          'SaleType': ['None', 'WD', 'New', 'COD', 'ConLD', 'ConLI', 'CWD', 'ConLw', 'Con', 'Oth'], \n",
    "          'SaleCondition': ['None', 'Normal', 'Abnorml', 'Partial', 'AdjLand', 'Alloca', 'Family']}\n",
    "\n",
    "def nominal_encode(df):\n",
    "    X = df.copy()\n",
    "    # Ordinal categories\n",
    "    for name, levels in unordered_levels.items():\n",
    "        X[name] = X[name].astype(CategoricalDtype(levels, ordered=False))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "657e52be-588c-4ce2-ac5d-d78f1e756ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorize ordered categorical features with label encoding\n",
    "def label_encode(df):\n",
    "    X = df.copy()\n",
    "    # The `cat.codes` attribute holds the category levels.\n",
    "    for colname in X.select_dtypes([\"category\"]).columns:\n",
    "        if X[colname].cat.ordered:  # Check if the categorical column is ordered\n",
    "            X[colname] = X[colname].cat.codes\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91fd8688-53f4-45de-b45b-e282b42457c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create features with pandas\n",
    "def create_features_pandas(df):\n",
    "    \n",
    "    X = df.copy()\n",
    "    \n",
    "    # mathematical_transforms:\n",
    "    X[\"LivLotRatio\"] = X[\"GrLivArea\"] / X[\"LotArea\"]\n",
    "    X[\"Spaciousness\"] = (X[\"FirstFlrSF\"] + X[\"SecondFlrSF\"]) / X[\"TotRmsAbvGrd\"]\n",
    "    X['NewHouse_RecentRemodel'] = 2*(X['YearBuilt']/2010) + (X['YearRemodAdd'] - X['YearBuilt'])/2010 \n",
    "                                  # check the plot for 'SAlePrice' vs 'YearBuilt' and 'YearRemodAdd' in section B\n",
    "        \n",
    "    X['TotalSF'] = X['TotalBsmtSF'] + X['FirstFlrSF'] + X['SecondFlrSF'] \n",
    "    X['TotalSF2'] = X['BsmtFinSF1'] + X['BsmtFinSF2'] + X['FirstFlrSF'] + X['SecondFlrSF']\n",
    "    X['TotalBathrooms'] = X['FullBath'] + (0.5*X['HalfBath']) + X['BsmtFullBath'] + (0.5*X['BsmtHalfBath'])\n",
    "    X['TotalPorchArea'] = X['OpenPorchSF'] + X['Threeseasonporch'] + X['EnclosedPorch'] + X['ScreenPorch'] + X['WoodDeckSF']\n",
    "    \n",
    "    X[\"OverallGrade\"] = np.sqrt(X[\"OverallQual\"] * X[\"OverallCond\"])\n",
    "    X[\"GarageGrade\"] = np.sqrt(X[\"GarageQual\"] * X[\"GarageCond\"])\n",
    "    X[\"ExterGrade\"] = np.sqrt(X[\"ExterQual\"] * X[\"ExterCond\"])\n",
    "    \n",
    "    # special features\n",
    "    X['HasPool'] = X['PoolArea'].apply(lambda x: 1 if x > 0 else 0)                                                                          \n",
    "    X['Has2ndfloor'] = X['SecondFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    X['HasGarage'] = X['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    X['HasBasement'] = X['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    X['HasFireplace'] = X['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    X[\"HasShed\"] = (X[\"MiscFeature\"] == \"Shed\") * 1 \n",
    "    X[\"RemodelbeforeSold\"] = (X[\"YearRemodAdd\"] == X[\"YrSold\"])*1  # True(1) if a remodelling happened in the same year the house was sold\n",
    "    \n",
    "    X.loc[X.Neighborhood == 'NridgHt', \"GoodNeighborhood\"] = 1\n",
    "    X.loc[X.Neighborhood == 'Crawfor', \"GoodNeighborhood\"] = 1\n",
    "    X.loc[X.Neighborhood == 'StoneBr', \"GoodNeighborhood\"] = 1\n",
    "    X.loc[X.Neighborhood == 'Somerst', \"GoodNeighborhood\"] = 1\n",
    "    X.loc[X.Neighborhood == 'NoRidge', \"GoodNeighborhood\"] = 1\n",
    "    X[\"GoodNeighborhood\"].fillna(0, inplace=True)\n",
    "\n",
    "    X[\"AbnormalSaleCondition\"] = X.SaleCondition.replace({'Abnorml': 1, 'Alloca': 1, 'AdjLand': 1, 'Family': 1, 'Normal': 0, 'Partial': 0}) \n",
    "    X[\"PartialSale\"] = X.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1}) \n",
    "    X[\"GoodHeating\"] = X.HeatingQC.replace({'Ex': 1, 'Gd': 1, 'TA': 0, 'Fa': 0, 'Po': 0})\n",
    "\n",
    "    area_cols = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "                 'TotalBsmtSF', 'FirstFlrSF', 'SecondFlrSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', \n",
    "                 'OpenPorchSF', 'EnclosedPorch', 'Threeseasonporch', 'ScreenPorch', 'LowQualFinSF', 'PoolArea']\n",
    "    X[\"TotalHouseArea\"] = X[area_cols].sum(axis=1) \n",
    "\n",
    "    X[\"TotalArea1st2nd\"] = X[\"FirstFlrSF\"] + X[\"SecondFlrSF\"]\n",
    "    X[\"HouseAge\"] = 2010 - X[\"YearBuilt\"]\n",
    "    X['SoldAge'] = X.YrSold - X.YearBuilt\n",
    "       \n",
    "    neighborhood = {\"MeadowV\" : 0,  \"IDOTRR\" : 1, \"BrDale\" : 1, \"OldTown\" : 1, \"Edwards\" : 1, \"BrkSide\" : 1, \"Sawyer\" : 1, \n",
    "                    \"Blueste\" : 1, \"SWISU\" : 2, \"NAmes\" : 2,  \"NPkVill\" : 2, \"Mitchel\" : 2, \"SawyerW\" : 2, \"Gilbert\" : 2, \n",
    "                    \"NWAmes\" : 2, \"Blmngtn\" : 2, \"CollgCr\" : 2, \"ClearCr\" : 3, \"Crawfor\" : 3, \"Veenker\" : 2, \"Somerst\" : 3, \n",
    "                    \"Timber\" : 3, \"StoneBr\" : 3, \"NridgHt\" : 3, \"NoRidge\" : 4}\n",
    "\n",
    "    X[\"NeighborhoodMap\"] = X[\"Neighborhood\"].map(neighborhood)\n",
    "    \n",
    "\n",
    "    # logarithmic features from highly skewed features\n",
    "    X[\"GrLivArea_log\"] = np.log1p(X.GrLivArea)\n",
    "    X['MasVnrArea_log'] = np.log1p(X.MasVnrArea)\n",
    "\n",
    "\n",
    "    # interaction features\n",
    "    # Replace pd.get_dummies with a check\n",
    "    if 'BldgType_Interaction_None' not in X.columns:  # Check against existing columns\n",
    "        X1 = pd.get_dummies(X.BldgType, prefix=\"BldgType_Interaction\")\n",
    "        X1 = X1.mul(X.GrLivArea, axis=0)\n",
    "        X = pd.concat([X, X1], axis=1)\n",
    "        \n",
    "    # Replace pd.get_dummies with a check\n",
    "    if 'Neighborhood_Interaction_None' not in X.columns:  # Check against existing columns\n",
    "        X2 = pd.get_dummies(X.Neighborhood, prefix=\"Neighborhood_Interaction\")\n",
    "        X2 = X2.mul(X.GrLivArea, axis=0)\n",
    "        X = pd.concat([X, X2], axis=1)\n",
    "    \n",
    "    # counts features\n",
    "    X[\"PorchTypes\"] = X[[\n",
    "        \"WoodDeckSF\",\n",
    "        \"OpenPorchSF\",\n",
    "        \"EnclosedPorch\",\n",
    "        \"Threeseasonporch\",\n",
    "        \"ScreenPorch\",\n",
    "    ]].gt(0.0).sum(axis=1)\n",
    "\n",
    "    # group_transforms features\n",
    "    X[\"MedNhbdArea\"] = X.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n",
    "  \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a973684c-fa9c-4693-8a36-1898dcf51bb8",
   "metadata": {},
   "source": [
    "#### Combine all data preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc737975-8d02-47c9-8d49-732e36935ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \n",
    "    X = df.copy()\n",
    "    \n",
    "    # rename columns\n",
    "    X = rename_columns(X)\n",
    "    \n",
    "    # clean X\n",
    "    X = clean(X)\n",
    "    \n",
    "    # nominal (unordered categorical) encode X\n",
    "    X = numer_to_object(X)\n",
    "    \n",
    "    # impute NAs\n",
    "    X = impute(X)\n",
    "    \n",
    "    # ordinal (ordered categorical) encode X\n",
    "    X = ordinal_encode(X)\n",
    "    \n",
    "    # nominal (unordered categorical) encode X\n",
    "    X = nominal_encode(X)\n",
    "    \n",
    "    # factorize ordered categorical features\n",
    "    X = label_encode(X)\n",
    "    \n",
    "    # create features with pandas\n",
    "    X = create_features_pandas(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213723d9-0e0e-43cf-bf33-ea1eb21a8565",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682b19ec-0d33-4c18-ba17-78fdb4bfe102",
   "metadata": {
    "papermill": {
     "duration": 0.035245,
     "end_time": "2022-08-21T06:38:52.430331",
     "exception": false,
     "start_time": "2022-08-21T06:38:52.395086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01b48920-84ee-4b1f-860a-6cca767a180c",
   "metadata": {
    "papermill": {
     "duration": 0.043636,
     "end_time": "2022-08-21T06:38:52.509441",
     "exception": false,
     "start_time": "2022-08-21T06:38:52.465805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGB Regressor\n",
    "xgb_params = dict(max_depth= 4,\n",
    "                  learning_rate= 0.005005070416155941,\n",
    "                  n_estimators= 7650,\n",
    "                  min_child_weight= 2,\n",
    "                  colsample_bytree= 0.20263034530849983,\n",
    "                  subsample= 0.4402289758648288,\n",
    "                  reg_alpha= 0.0010309970136600966,\n",
    "                  reg_lambda= 0.012884368300273313,\n",
    "                  random_state=1)\n",
    "                  \n",
    "\n",
    "xgb =  XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e78335-a20d-48bf-bc65-6451bd458c83",
   "metadata": {
    "papermill": {
     "duration": 0.034729,
     "end_time": "2022-08-21T06:38:52.730180",
     "exception": false,
     "start_time": "2022-08-21T06:38:52.695451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03ad6191-8aae-4a42-b257-378dfb91af78",
   "metadata": {
    "papermill": {
     "duration": 0.043229,
     "end_time": "2022-08-21T06:38:52.808718",
     "exception": false,
     "start_time": "2022-08-21T06:38:52.765489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = 6, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a3d9c8-0be2-436b-a32b-eedb074a8c4a",
   "metadata": {
    "papermill": {
     "duration": 0.035084,
     "end_time": "2022-08-21T06:38:52.880559",
     "exception": false,
     "start_time": "2022-08-21T06:38:52.845475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f4dcc50-2f9e-4991-bc41-510e68b67446",
   "metadata": {
    "papermill": {
     "duration": 0.042582,
     "end_time": "2022-08-21T06:38:52.958799",
     "exception": false,
     "start_time": "2022-08-21T06:38:52.916217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "elasticnet = ElasticNet(max_iter=1000,\n",
    "                        alpha=0.0007,\n",
    "                        l1_ratio=0.9,\n",
    "                        random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2328ff6a-722b-416f-83a8-f2cc5b0572bc",
   "metadata": {
    "papermill": {
     "duration": 0.035814,
     "end_time": "2022-08-21T06:38:52.206278",
     "exception": false,
     "start_time": "2022-08-21T06:38:52.170464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Create Stacking model for improved prediction\n",
    "Stacking is an ensemble machine learning technique in which the outputs of multiple different machine learning models (base models) are fed into a higher-level meta-model to make the final output. Stacking can be useful to improve the overall accuracy of the predictions by utilising the strengths of each individual base model and minimising the effects of overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "274c26db-c110-4fb1-8bac-3f51446d6cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('elasticnet', elasticnet),\n",
    "    ('xgb', xgb)\n",
    "]\n",
    "\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "stack = StackingRegressor(estimators=base_models, final_estimator=meta_model, cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794987c1-24d0-4219-87ca-5f89553240c9",
   "metadata": {},
   "source": [
    "## End-to-end ML pipeline with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c203145-6eb5-4fb3-b310-0ed890e09095",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;data_preprocessor&#x27;, DataPreprocessor()),\n",
       "                (&#x27;transform&#x27;,\n",
       "                 ColumnTransformerWrapper(preprocessor=DataPreprocessor())),\n",
       "                (&#x27;stack&#x27;,\n",
       "                 StackingRegressor(cv=5,\n",
       "                                   estimators=[(&#x27;elasticnet&#x27;,\n",
       "                                                ElasticNet(alpha=0.0007,\n",
       "                                                           l1_ratio=0.9,\n",
       "                                                           random_state=1)),\n",
       "                                               (&#x27;xgb&#x27;,\n",
       "                                                XGBRegressor(base_score=None,\n",
       "                                                             booster=None,\n",
       "                                                             callbacks=None,\n",
       "                                                             colsample_bylevel=None,\n",
       "                                                             colsample_bynode=None,...\n",
       "                                                             interaction_constraints=None,\n",
       "                                                             learning_rate=0.005005070416155941,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=4,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=2,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             n_estimators=7650,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             predictor=None,\n",
       "                                                             random_state=1, ...))],\n",
       "                                   final_estimator=LinearRegression()))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;data_preprocessor&#x27;, DataPreprocessor()),\n",
       "                (&#x27;transform&#x27;,\n",
       "                 ColumnTransformerWrapper(preprocessor=DataPreprocessor())),\n",
       "                (&#x27;stack&#x27;,\n",
       "                 StackingRegressor(cv=5,\n",
       "                                   estimators=[(&#x27;elasticnet&#x27;,\n",
       "                                                ElasticNet(alpha=0.0007,\n",
       "                                                           l1_ratio=0.9,\n",
       "                                                           random_state=1)),\n",
       "                                               (&#x27;xgb&#x27;,\n",
       "                                                XGBRegressor(base_score=None,\n",
       "                                                             booster=None,\n",
       "                                                             callbacks=None,\n",
       "                                                             colsample_bylevel=None,\n",
       "                                                             colsample_bynode=None,...\n",
       "                                                             interaction_constraints=None,\n",
       "                                                             learning_rate=0.005005070416155941,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=4,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=2,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             n_estimators=7650,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             predictor=None,\n",
       "                                                             random_state=1, ...))],\n",
       "                                   final_estimator=LinearRegression()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DataPreprocessor</label><div class=\"sk-toggleable__content\"><pre>DataPreprocessor()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transform: ColumnTransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformerWrapper(preprocessor=DataPreprocessor())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: DataPreprocessor</label><div class=\"sk-toggleable__content\"><pre>DataPreprocessor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DataPreprocessor</label><div class=\"sk-toggleable__content\"><pre>DataPreprocessor()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">stack: StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(cv=5,\n",
       "                  estimators=[(&#x27;elasticnet&#x27;,\n",
       "                               ElasticNet(alpha=0.0007, l1_ratio=0.9,\n",
       "                                          random_state=1)),\n",
       "                              (&#x27;xgb&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.20263034530849983,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gp...\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.005005070416155941,\n",
       "                                            max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=4,\n",
       "                                            max_leaves=None, min_child_weight=2,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=7650, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=1, ...))],\n",
       "                  final_estimator=LinearRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>elasticnet</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.0007, l1_ratio=0.9, random_state=1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.20263034530849983, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.005005070416155941,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=7650, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=1, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('data_preprocessor', DataPreprocessor()),\n",
       "                ('transform',\n",
       "                 ColumnTransformerWrapper(preprocessor=DataPreprocessor())),\n",
       "                ('stack',\n",
       "                 StackingRegressor(cv=5,\n",
       "                                   estimators=[('elasticnet',\n",
       "                                                ElasticNet(alpha=0.0007,\n",
       "                                                           l1_ratio=0.9,\n",
       "                                                           random_state=1)),\n",
       "                                               ('xgb',\n",
       "                                                XGBRegressor(base_score=None,\n",
       "                                                             booster=None,\n",
       "                                                             callbacks=None,\n",
       "                                                             colsample_bylevel=None,\n",
       "                                                             colsample_bynode=None,...\n",
       "                                                             interaction_constraints=None,\n",
       "                                                             learning_rate=0.005005070416155941,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=4,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=2,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             n_estimators=7650,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             predictor=None,\n",
       "                                                             random_state=1, ...))],\n",
       "                                   final_estimator=LinearRegression()))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Put all the data processing steps into a Custom Transformer\n",
    "class DataPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.numeric_cols = None\n",
    "        self.categorical_cols = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_transformed = self.transform(X)\n",
    "        self.numeric_cols = X_transformed.select_dtypes(include=['number']).columns.tolist()\n",
    "        self.categorical_cols = X_transformed.select_dtypes(exclude=['number']).columns.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X = preprocess(X)\n",
    "        return X\n",
    "    \n",
    "# Custom data/feature preprocessor\n",
    "data_preprocessor = DataPreprocessor()\n",
    "\n",
    "# scaler for numeric features\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# one-hot encoding for categorical features\n",
    "ohe = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "# Wrap ColumnTransformer to access dynamic feature names from the custom transformer\n",
    "class ColumnTransformerWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, preprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.column_transformer = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.preprocessor.fit(X)\n",
    "        numeric_cols = self.preprocessor.numeric_cols\n",
    "        categorical_cols = self.preprocessor.categorical_cols\n",
    "        self.column_transformer = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', scaler, numeric_cols),\n",
    "                ('cat', ohe, categorical_cols)\n",
    "            ],\n",
    "            remainder = 'drop'\n",
    "        )\n",
    "        self.column_transformer.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.column_transformer.transform(X)\n",
    "\n",
    "# Initialize the ColumnTransformerWrapper\n",
    "column_transformer = ColumnTransformerWrapper(data_preprocessor)\n",
    "\n",
    "# Stacking model\n",
    "stack = StackingRegressor(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('data_preprocessor', data_preprocessor),\n",
    "    ('transform', column_transformer),\n",
    "    ('stack', stack)\n",
    "])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "pipeline.fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a358f2d4-e0f3-4151-8b9a-d5ff20e701ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([123056.68816801, 161556.64668924, 182618.22643544, 195772.21916238,\n",
       "       186202.04479163])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction on a small part of test data\n",
    "# as the y was log-transformed during fitting/training the model, we need to exp-transform the predictions\n",
    "predictions = np.exp(pipeline.predict(X_test[0:5]))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e47deb4b-2b9a-4997-80fc-a1ffb7669421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id      SalePrice\n",
      "0  1461  122547.494684\n",
      "1  1462  160890.136000\n",
      "2  1463  183593.913330\n",
      "3  1464  196901.009207\n",
      "4  1465  186396.020409\n"
     ]
    }
   ],
   "source": [
    "# make prediction on full test data\n",
    "# as the y was log-transformed during fitting/training the model, we need to exp-transform the predictions\n",
    "predictions = np.exp(pipeline.predict(X_test))\n",
    "output = pd.DataFrame({'Id': test.index, 'SalePrice': predictions})\n",
    "output.to_csv('y_pred.csv', index=False)\n",
    "print(output.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9eaddd2-4cdf-488e-b2d4-ca3b00d4dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook run time: 82 seconds\n"
     ]
    }
   ],
   "source": [
    "time_end = time.time()\n",
    "print(\"Notebook run time: {:.0f} seconds\".format(time_end - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fdda3b-957a-4783-a0d2-ba2d71379cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 265.625445,
   "end_time": "2022-08-21T06:42:15.128850",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-21T06:37:49.503405",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
